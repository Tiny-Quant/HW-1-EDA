---
title: "Exploratory Data Analysis"
author: "Art Tay"
output: pdf_document
---

```{r setup, include=FALSE}
##Setup code
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Report
```{r, include = F}
# EDA

# What can we learn about different hosts and areas?

# What can we learn from predictions? (ex: locations, prices, reviews, etc)

# Which hosts are the busiest and why?
    ## Possible variable:
        # avaliability_x. The availability of the listing x days
        # in the future as determined by the calendar.
        # Note a listing may not be available because it has been
        # booked by a guest or blocked by the host.

# Is there any noticeable difference of traffic among different areas
# and what could be the reason for it?

#Note: Don't forget get to check for missing data, skewed data, outliers.....
```

# Appendix - Code

```{r}
# Libraries
library(VIM)
library(mice)
library(naniar)
library(tidyverse)
library(fastDummies)
library(NbClust)
library(kernlab)
```

```{r}
# Load in Data
data_full <- read.csv("AB_NYC_2019.csv", stringsAsFactors = T, header = T)
#dim(data_full)
#colnames(data_full)
#str(data_full)
```

## Data Cleaning
```{r}
# Data cleaning

# Removing uninformative variables (names).
data_quant <- data_full %>% select(-c(id, host_id, name, host_name))
#str(data_quant)
```

### Missing Data

```{r}
# Missing data.

# Code value that might mean missing.
# price == 0 -> NA
# lattitude == 0 -> NA
# longitude == 0 -> NA
# min_night == 0 -> NA
data_quant_mis <- data_quant %>%
    mutate(price = ifelse(price == 0, NA, price)) %>%
    mutate(latitude = ifelse(latitude == 0, NA, latitude)) %>%
    mutate(longitude = ifelse(longitude == 0, NA, longitude)) %>%
    mutate(minimum_nights = ifelse(minimum_nights == 0, NA, minimum_nights)) %>%
    # It was done using replace to maintain factor coding
    mutate(room_type = replace(room_type,
        room_type == "" | room_type == " ", NA)) %>%
    mutate(neighbourhood_group = replace(neighbourhood_group,
        neighbourhood_group == "" | neighbourhood_group == " ",  NA)) %>%
    mutate(neighbourhood = replace(neighbourhood,
        neighbourhood == "" | neighbourhood == " ", NA)) %>%
    mutate(last_review = replace(last_review,
        last_review == "" | room_type == " ", NA))

# data_quant_mis <- as.data.frame(data_quant_mis)

#colnames(data_quant_mis) <- colnames(data_quant)
str(data_quant_mis)
```

```{r, include = F}
# Plot the percentage and patterns of missing values.
missing_percent <- apply(data_quant_mis, MARGIN = 2,
    FUN = function(x){sum(is.na(x)) / length(x)})

# Filter out non-missing variables
missing_percent <- as.data.frame(missing_percent) %>%
                   filter(missing_percent > 0)

# Add variable names to the data frame.
missing_percent$Variable <- c("price", "last review date", "reviews per month")

# Round and change proportion to percentages.
missing_percent$missing_percent <- round(
        missing_percent$missing_percent * 100, 2)

plot_1 <- missing_percent %>%
          ggplot(aes(x = reorder(Variable, missing_percent),
            y = missing_percent, fill = Variable)) +
          geom_bar(stat = "identity") +
          geom_text(aes(label = missing_percent), vjust = 1.6) +
          theme_bw() + theme(legend.position = "none") +
          ggtitle("Percentages of Missing Values by Variable") +
          ylab("Percent Missing") + xlab("")
```

```{r}
# Plot the pattern of missing values
gg_miss_upset(data_quant_mis, nintersects = NA, text.scale = 2,
    mainbar.y.label = "Count of Observations with Missing Data",
    point.size = 5, line.size = 2, matrix.color = "orange",
    main.bar.color = "skyblue")
```

```{r}
# Check the subset of points with missing prices.
mis_price <- data_full %>% filter(price == 0)

# Only 3 are missing availability.
# Most in Brooklyn, but no clear relationship.
# Seem to be MAR.
# Imputation seems valid.

# Check if all last review and number review missing together.
sum(is.na(data_quant_mis$last_review) &
    !is.na(data_quant_mis$reviews_per_month))

mis_reviews <- data_full %>% filter(is.na(data_quant_mis$last_review)) %>%
                select(reviews_per_month, last_review, number_of_reviews)

# There two values are always missing together.
# Check if total review is zero also.
sum(mis_reviews$number_of_reviews > 0)

# Number of Review, Reviews per month, and last review date are all missing
# together.
```

### Feature Engineering
```{r}
# Handles all missing values that are not price
data_quant_fe <- data_quant_mis %>%
                 # Change NA reviews per month to be 0.
                 mutate(reviews_per_month =
                    ifelse(is.na(reviews_per_month), 0, reviews_per_month))%>%
                 # Create a new variable last_review_year to reduce dimensionality.
                 mutate(last_review_year = substring(last_review, 1, 4)) %>%
                 # Modify NA last_review to be a new level "none".
                 mutate(last_review_year = replace(last_review_year,
                    is.na(last_review_year), "none")) %>%
                 # Cast to be factor.
                 mutate(last_review_year = as.factor(last_review_year)) %>%
                 # Remove old last review variable
                 select(-last_review) %>%
                 # natural log transform price.
                 mutate(price = log(price))
# str(data_quant_fe)
```

```{r}
# Centering a scale numerics.
data_quant_mis_numeric <- data_quant_fe %>% select(where(is.numeric))

# Retain vector to enable back transformation.
means <- apply(data_quant_mis_numeric, MARGIN = 2, FUN = mean, na.rm = T)
sds <- apply(data_quant_mis_numeric, MARGIN = 2, FUN = sd, na.rm = T)

# Apply transformation
for(i in 1:length(means)){
    data_quant_mis_numeric[, i] <-
        (data_quant_mis_numeric[, i] - means[i]) / sds[i]
}

# Tests
#means_2 <- apply(data_quant_mis_numeric, MARGIN = 2, FUN = mean, na.rm = T)
#sds_2 <- apply(data_quant_mis_numeric, MARGIN = 2, FUN = sd, na.rm = T)

# Back transformation code.
#for(i in 1:length(means)){
    #data_quant_mis_numeric[, i] <-
        #data_quant_mis_numeric[, i] * sds[i] + means[i]
#}
```

```{r}
# Dummy variables (one-hot-encoding)
data_quant_mis_factor <- data_quant_fe %>% select(where(is.factor)) %>%
                                           # too many levels.
                                           select(-neighbourhood)

data_quant_mis_factor <- dummy_cols(data_quant_mis_factor,
                                    remove_selected_columns = T)
```

```{r}
# Combine cleaned data set for imputation.
data_quant_clean <- cbind(data_quant_mis_numeric, data_quant_mis_factor)
```

```{r, cache = T}
# kNN imputeation with k = 10
data_quant_clean_imputed <- VIM::kNN(as.matrix(data_quant_clean), k = 10)

# Create a factor based on whether or not price as imputed
impStatus <- as.numeric(data_quant_clean_imputed$price_imp)

# get the original columns
data_quant_clean_imputed <- data_quant_clean_imputed[, 1:26]
data_quant_clean_imputed$impStatus <- impStatus

# Check 11 imputed values
#sum(data_quant_clean_imputed$impStatus)
```

## Clustering
```{r, cache = T}
#data_clusters <- NbClust(data = data_quant_clean_imputed,
                         #distance = "euclidean",
                         #method = "ward.D",
                         #index = "silhouette")
```

```{r}
#save(data_clusters, file = "data_clusters.rds")
load(file = "data_clusters.rds")
```

```{r}
# Dummy variables (one-hot-encoding)
factor_all <- data_quant_fe %>% select(where(is.factor))

factor_all <- dummy_cols(factor_all,
                         remove_selected_columns = T)
```

```{r}
# Combine cleaned data set for imputation.
data_clean_all <- cbind(data_quant_mis_numeric, factor_all)
```

```{r, cache = T}
# kNN imputeation with k = 10
data_clean_imputed_all <- VIM::kNN(as.matrix(data_clean_all), k = 10)

# Create a factor based on whether or not price as imputed
impStatus <- as.numeric(data_clean_imputed_all$price_imp)

# get the original columns
data_clean_imputed_all <- data_clean_imputed_all[, 1:247]
data_clean_imputed_all$impStatus <- impStatus

# Check 11 imputed values
sum(data_clean_imputed_all$impStatus)
```

```{r, cache = T}
#data_clusters_2 <- NbClust(data = data_clean_imputed_all,
                         #distance = "euclidean",
                         #method = "ward.D",
                         #index = "silhouette")
```

```{r}
#save(data_clusters_2, file = "data_clusters_2.rds")
load(file = "data_clusters_2.rds")
```

## Kernel Based Clustering
```{r}
#rbf <- rbfdot(sigma = 0.05)
#kernel_distances <- kernelMatrix(
    #kernel = rbf,
    #x = as.matrix(data_quant_clean_imputed))
```

```{r}
#save(kernel_distances, file = "kernel_distances.rds")
#load("kernel_distances.rds")
```

```{r}
#kernel_clusters <- NbClust(data = data_quant_clean_imputed,
                           #diss = kernel_distances,
                           #distance = NULL,
                           #method = "ward.D",
                           #min.nc = 2,
                           #max.nc = 20,
                           #index = "silhouette")
```

## Investigation of Clusters

### Cluster 1 cleaning
```{r}
# Back Transform numeric data.
# Extract numeric columns.
data_imputed_numeric <- data_quant_clean_imputed %>%
                        select(1:8)

# Undo centering and scaling.
for(i in 1:length(means)){
    data_imputed_numeric[, i] <-
        data_imputed_numeric[, i] * sds[i] + means[i]
}

# Undo log transformation on price.
data_imputed_numeric <- data_imputed_numeric %>%
                        mutate(price = exp(price)) %>%
                        # fixes rounding error
                        mutate(availability_365 = round(availability_365))
```

```{r}
# Extract original factor formats.
data_imputed_factor <- data_quant_fe %>% select(where(is.factor))

# Confirm no missing
#sum(is.na(data_imputed_factor))
```

```{r}
data_clean_cluster_1 <- cbind(data_imputed_numeric,
                              data_imputed_factor,
                              "impStatus" = as.factor(
                                    data_quant_clean_imputed$impStatus),
                              "Cluster" = as.factor(
                                    data_clusters$Best.partition))
```

### Cluster 2 cleaning
```{r}
# Back Transform numeric data.
# Extract numeric columns.
data_imputed_numeric_all <- data_clean_imputed_all %>%
                        select(1:8)

# Undo centering and scaling.
for(i in 1:length(means)){
    data_imputed_numeric_all[, i] <-
        data_imputed_numeric_all[, i] * sds[i] + means[i]
}

# Undo log transformation on price.
data_imputed_numeric_all <- data_imputed_numeric_all %>%
                            mutate(price = exp(price)) %>%
                            # fixes rounding error
                            mutate(availability_365 = round(availability_365))
```

```{r}
data_clean_cluster_2 <- cbind(data_imputed_numeric_all,
                              data_imputed_factor,
                              "impStatus" = as.factor(
                                    data_clean_imputed_all$impStatus),
                              "Cluster" = as.factor(
                                    data_clusters_2$Best.partition))
```

# Visualizations
```{r}
# boxplot by neighborhood
plot_x <- data_quant %>%
    ggplot(aes(x = neighbourhood_group, y = log(price))) +
    geom_boxplot()
```

## Cluster Statistics
### Clustering 1
```{r}
plot_prices_c1 <- data_clean_cluster_1 %>%
                  select(price, Cluster) %>%
                  ggplot(aes(price)) +
                  geom_histogram() +
                  facet_wrap(~Cluster)

cluster_summary_numeric <- data_clean_cluster_1 %>% group_by(Cluster) %>%
                          summarise(across(where(is.numeric),
                          list(median = median, sd = sd)))

#layered density plot > data table


cluster_summary_factor <- data_clean_cluster_1 %>%
                          select(where(is.factor)) %>%
                          select(-impStatus) %>%
                          select(Cluster, neighbourhood_group) %>%
                          pivot_longer(!Cluster) %>%
                          count(Cluster, name, value, .drop = F, sort = T)
```

```{r}
plot_neighborhoods <- cluster_summary_factor %>%
           ggplot(aes(x = value, y = n, col = value)) +
           geom_bar(stat = 'identity') +
           facet_wrap(~Cluster, scales = "free_x")
```

## Check Skewness
```{r}
# Histogram of all numerics
plot_xx <- data_quant %>%
           select(where(is.numeric)) %>%
           pivot_longer(cols = everything()) %>%
           ggplot(aes(value)) +
           geom_histogram() +
           facet_wrap(~name, scales = "free_x")
```